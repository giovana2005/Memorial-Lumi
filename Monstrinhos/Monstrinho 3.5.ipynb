{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<span style=\"font-family: 'Palatino Linotype', serif;\">‚öôÔ∏è‚ö°Forma, fun√ß√£o e ativa√ß√£o</span>**\n",
    "----\n",
    "*<span style=\"font-family: 'Angilla Tattoo'\"> \"\"Moldaremos a forma, otimizaremos a fun√ß√£o e executataremos a ativa√ß√£o da magia pato-digital para consquistar o Reino de Lumi! ü¶Üüíª‚ú®\"\"</span>*\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src = \"Maga Forma, Fun√ß√£o e ativa√ß√£o.jpg\" alt = \"Maga FFA\" width = 300>\n",
    "</div>\n",
    "\n",
    "----\n",
    " **Objetivo:** Nesse notebook, implementei 3 as fun√ß√µes de ativa√ß√£o fun√ß√£o liner, Tahn e Softmax, na rede neural feita em python em sala da aula. Realizo uma breve explica√ß√£o sobre as fun√ß√µes, mostando suas equa√ß√µes e diferen√ßas em rela√ß√£o a fun√ß√£o sigmoidal, e por fim s√£o feitos testes simples para comprovar seu funcionamento.\n",
    " \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìê A fun√ß√£o linear\n",
    "\n",
    "A fun√ß√£o √© definida como $$ f(x) = ax $$ por√©m, a fun√ß√£o linear √© constante, o que significa que o valor de sua derivada n√£o depende de X. Nesse sentido, o valor do gradiente local no backpropagation ser√° sempre o mesmo. Isso √© um grande problema, pois n√£o podemos melhorar a fun√ß√£o de perda \"loss\", e a sa√≠da final da nossa rede neural ser√° uma transforma√ß√£o linear dos dados de entrada. Isso faz com que essa fun√ß√£o de entrada seja interessante em contextos de problemas simples, onde desejamos que os resultados sejam interpret√°veis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c√≥digo que cria a classe Valor para opera√ß√µes matem√°ticas feito em sala de aula \n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "class Valor_linear:\n",
    "    def __init__(self, data, progenitor=(), operador_mae=\"\", rotulo=\"\"):\n",
    "        self.data = data\n",
    "        self.progenitor = progenitor\n",
    "        self.operador_mae = operador_mae\n",
    "        self.rotulo = rotulo\n",
    "        self.grad = 0\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Valor(data={self.data})\"\n",
    "    \n",
    "    def __add__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: self + outro_valor.\"\"\"\n",
    "        \n",
    "        if not isinstance(outro_valor, Valor_linear):\n",
    "            outro_valor = Valor_linear(outro_valor)\n",
    "            \n",
    "        progenitor = (self, outro_valor)\n",
    "        data = self.data + outro_valor.data\n",
    "        operador_mae = \"+\"\n",
    "        resultado = Valor_linear(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_adicao():\n",
    "            self.grad += resultado.grad\n",
    "            outro_valor.grad += resultado.grad\n",
    "            \n",
    "        resultado.propagar = propagar_adicao\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __mul__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: self * outro_valor.\"\"\"\n",
    "        \n",
    "        if not isinstance(outro_valor, Valor_linear):\n",
    "            outro_valor = Valor_linear(outro_valor)\n",
    "            \n",
    "        progenitor = (self, outro_valor)\n",
    "        data = self.data * outro_valor.data\n",
    "        operador_mae = \"*\"\n",
    "        resultado = Valor_linear(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_multiplicacao():\n",
    "            self.grad += resultado.grad * outro_valor.data # grad_filho * derivada filho em rela√ß√£o a m√£e\n",
    "            outro_valor.grad += resultado.grad * self.data\n",
    "            \n",
    "        resultado.propagar = propagar_multiplicacao\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def exp(self):\n",
    "        \"\"\"Realiza a opera√ß√£o: exp(self)\"\"\"\n",
    "        progenitor = (self, )\n",
    "        data = math.exp(self.data)\n",
    "        operador_mae = \"exp\"\n",
    "        resultado = Valor_linear(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_exp():\n",
    "            self.grad += resultado.grad * data \n",
    "        \n",
    "        resultado.propagar = propagar_exp\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __pow__(self, expoente):\n",
    "        \"\"\"Realiza a opera√ß√£o: self ** expoente\"\"\"\n",
    "        assert isinstance(expoente, (int, float))\n",
    "        progenitor = (self, )\n",
    "        data = self.data ** expoente\n",
    "        operador_mae = f\"**{expoente}\"\n",
    "        resultado = Valor_linear(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_pow():\n",
    "            self.grad += resultado.grad * (expoente * self.data ** (expoente - 1))\n",
    "        \n",
    "        resultado.propagar = propagar_pow\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __truediv__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: self / outro_valor\"\"\"\n",
    "        return self * outro_valor ** (-1)\n",
    "    \n",
    "    def __neg__(self):\n",
    "        \"\"\"Realiza a opera√ß√£o: -self\"\"\"\n",
    "        return self * -1\n",
    "    \n",
    "    def __sub__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: self - outro_valor\"\"\"\n",
    "        return self + (-outro_valor)\n",
    "    \n",
    "    def __radd__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: outro_valor + self\"\"\"\n",
    "        return self + outro_valor\n",
    "    \n",
    "    def __rmul__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: outro_valor * self\"\"\"\n",
    "        return self * outro_valor\n",
    "    \n",
    "    ### fun√ß√£o criada para realizar uma opera√ß√£o linear para cte = 2\n",
    "    def funcao_linear(self):\n",
    "        \"\"\"Realiza a opera√ß√£o: x * cte = 2)\"\"\"\n",
    "        return self.data * 2\n",
    "    \n",
    "    def propagar(self):\n",
    "        pass\n",
    "    \n",
    "    def propagar_tudo(self):\n",
    "        \n",
    "        self.grad = 1\n",
    "        \n",
    "        ordem_topologica = []\n",
    "        \n",
    "        visitados = set()\n",
    "\n",
    "        def constroi_ordem_topologica(v):\n",
    "            if v not in visitados:\n",
    "                visitados.add(v)\n",
    "                for progenitor in v.progenitor:\n",
    "                    constroi_ordem_topologica(progenitor)\n",
    "                ordem_topologica.append(v)\n",
    "\n",
    "        constroi_ordem_topologica(self)\n",
    "        \n",
    "        for vertice in reversed(ordem_topologica):\n",
    "            vertice.propagar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c√≥digo que cria um neur√¥nio artificial, feito em sala\n",
    "import random\n",
    "\n",
    "class Neuronio_linear:\n",
    "    def __init__(self, num_dados_entrada):\n",
    "        self.vies = Valor_linear(random.uniform(-1, 1))\n",
    "        \n",
    "        self.pesos = []\n",
    "        for i in range(num_dados_entrada):\n",
    "            self.pesos.append(Valor_linear(random.uniform(-1, 1)))\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        \n",
    "        assert len(x) == len(self.pesos)\n",
    "        \n",
    "        soma = 0\n",
    "        for info_entrada, peso_interno in zip(x, self.pesos):\n",
    "            soma += info_entrada * peso_interno\n",
    "            \n",
    "        soma += self.vies  \n",
    "        ### utiliza a fun√ß√£o linear\n",
    "        dado_de_saida = soma.funcao_linear()\n",
    "        \n",
    "        return dado_de_saida       \n",
    "    \n",
    "    def parametros(self):\n",
    "        return self.pesos + [self.vies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.856031282555648\n"
     ]
    }
   ],
   "source": [
    "dados_de_entrada = [2, 3]\n",
    "\n",
    "meu_neuronio = Neuronio_linear(len(dados_de_entrada))\n",
    "\n",
    "print(meu_neuronio(dados_de_entrada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "### c√≥digo que cria uma camada de neur√¥nios, feito em sala de aula\n",
    "class Camada_linear:\n",
    "    def __init__(self, num_neuronios, num_dados_entrada):\n",
    "        neuronios = []\n",
    "        \n",
    "        for _ in range(num_neuronios):\n",
    "            neuronio = Neuronio_linear(num_dados_entrada)\n",
    "            neuronios.append(neuronio)\n",
    "            \n",
    "        self.neuronios = neuronios     \n",
    "        \n",
    "    def __call__(self, x):\n",
    "        dados_de_saida = []\n",
    "        \n",
    "        for neuronio in self.neuronios:\n",
    "            informacao = neuronio(x)\n",
    "            dados_de_saida.append(informacao)\n",
    "            \n",
    "        if len(dados_de_saida) == 1:\n",
    "            return dados_de_saida[0]\n",
    "        else:        \n",
    "            return dados_de_saida  \n",
    "    \n",
    "    def parametros(self):\n",
    "        params = []\n",
    "        \n",
    "        for neuronio in self.neuronios:\n",
    "            params_neuronio = neuronio.parametros()\n",
    "            params.extend(params_neuronio)\n",
    "        \n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7986996356107419, 1.655596993787948, 1.3340024824702437, 0.286036242399208, -5.879968300999648]\n"
     ]
    }
   ],
   "source": [
    "dados_de_entrada = [2, 3]\n",
    "num_neuronios = 5\n",
    "\n",
    "minha_camada = Camada_linear(num_neuronios, len(dados_de_entrada))\n",
    "\n",
    "print(minha_camada(dados_de_entrada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "### classe que cria a rede neural MLP feito em sala de aula\n",
    "class MLP_linear:\n",
    "    def __init__(self, num_dados_entrada, num_neuronios_por_camada):\n",
    "        \n",
    "        percurso = [num_dados_entrada] + num_neuronios_por_camada\n",
    "        \n",
    "        camadas = []\n",
    "        \n",
    "        for i in range(len(num_neuronios_por_camada)):\n",
    "            camada = Camada_linear(num_neuronios_por_camada[i], percurso[i])\n",
    "            camadas.append(camada)\n",
    "            \n",
    "        self.camadas = camadas\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for camada in self.camadas:\n",
    "            x = camada(x)\n",
    "        return x\n",
    "    \n",
    "    def parametros(self):\n",
    "        params = []\n",
    "        \n",
    "        for camada in self.camadas:\n",
    "            parametros_camada = camada.parametros()\n",
    "            params.extend(parametros_camada)\n",
    "            \n",
    "        return params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.309400619820966, 7.0043334443115235, -45.19398229100116, 43.06599885923687, -5.13645178937743]\n"
     ]
    }
   ],
   "source": [
    "dados_de_entrada = [2, 3]\n",
    "num_neuronios_por_camada = [2, 4, 5]\n",
    "\n",
    "minha_mlp = MLP_linear(len(dados_de_entrada), num_neuronios_por_camada)\n",
    "\n",
    "resultado = minha_mlp(dados_de_entrada)\n",
    "\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- \n",
    "\n",
    "###  üî¢ A fun√ß√£o Tanh\n",
    "\n",
    "A fun√ß√£o Tanh, ou tangente hiperb√≥lica, √© uma vers√£o escalonada da fun√ß√£o sigmoide, dada por $$ Tahn(x) = \\frac {e^x - e^{-x}}{e^x - e^{-x}} $$ A fun√ß√£o Tanh √© sim√©trica entre os valore 1 e -1, diferente do que ocorre na fun√ß√£o sigmoide, que √© sim√©trica entre 0 e 1. Essa simetria em rela√ß√£o a origem √© interessante para a rede neural na medida que evita que os valores propagados para o pr√≥ximo neuronio sejam sempre positivos. Como a fun√ß√£o n√£o √© linear, podemos realizar o backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c√≥digo que cria a classe Valor para opera√ß√µes matem√°ticas feito em sala de aula \n",
    "\n",
    "class Valor_tanh:\n",
    "    def __init__(self, data, progenitor=(), operador_mae=\"\", rotulo=\"\"):\n",
    "        self.data = data\n",
    "        self.progenitor = progenitor\n",
    "        self.operador_mae = operador_mae\n",
    "        self.rotulo = rotulo\n",
    "        self.grad = 0\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Valor(data={self.data})\"\n",
    "    \n",
    "    def __add__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: self + outro_valor.\"\"\"\n",
    "        \n",
    "        if not isinstance(outro_valor, Valor_tanh):\n",
    "            outro_valor = Valor_tanh(outro_valor)\n",
    "            \n",
    "        progenitor = (self, outro_valor)\n",
    "        data = self.data + outro_valor.data\n",
    "        operador_mae = \"+\"\n",
    "        resultado = Valor_tanh(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_adicao():\n",
    "            self.grad += resultado.grad\n",
    "            outro_valor.grad += resultado.grad\n",
    "            \n",
    "        resultado.propagar = propagar_adicao\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __mul__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: self * outro_valor.\"\"\"\n",
    "        \n",
    "        if not isinstance(outro_valor, Valor_tanh):\n",
    "            outro_valor = Valor_tanh(outro_valor)\n",
    "            \n",
    "        progenitor = (self, outro_valor)\n",
    "        data = self.data * outro_valor.data\n",
    "        operador_mae = \"*\"\n",
    "        resultado = Valor_tanh(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_multiplicacao():\n",
    "            self.grad += resultado.grad * outro_valor.data # grad_filho * derivada filho em rela√ß√£o a m√£e\n",
    "            outro_valor.grad += resultado.grad * self.data\n",
    "            \n",
    "        resultado.propagar = propagar_multiplicacao\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def exp(self):\n",
    "        \"\"\"Realiza a opera√ß√£o: exp(self)\"\"\"\n",
    "        progenitor = (self, )\n",
    "        data = math.exp(self.data)\n",
    "        operador_mae = \"exp\"\n",
    "        resultado = Valor_tanh(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_exp():\n",
    "            self.grad += resultado.grad * data \n",
    "        \n",
    "        resultado.propagar = propagar_exp\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __pow__(self, expoente):\n",
    "        \"\"\"Realiza a opera√ß√£o: self ** expoente\"\"\"\n",
    "        assert isinstance(expoente, (int, float))\n",
    "        progenitor = (self, )\n",
    "        data = self.data ** expoente\n",
    "        operador_mae = f\"**{expoente}\"\n",
    "        resultado = Valor_tanh(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_pow():\n",
    "            self.grad += resultado.grad * (expoente * self.data ** (expoente - 1))\n",
    "        \n",
    "        resultado.propagar = propagar_pow\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __truediv__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: self / outro_valor\"\"\"\n",
    "        return self * outro_valor ** (-1)\n",
    "    \n",
    "    def __neg__(self):\n",
    "        \"\"\"Realiza a opera√ß√£o: -self\"\"\"\n",
    "        return self * -1\n",
    "    \n",
    "    def __sub__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: self - outro_valor\"\"\"\n",
    "        return self + (-outro_valor)\n",
    "    \n",
    "    def __radd__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: outro_valor + self\"\"\"\n",
    "        return self + outro_valor\n",
    "    \n",
    "    def __rmul__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: outro_valor * self\"\"\"\n",
    "        return self * outro_valor\n",
    "    \n",
    "    ### fun√ß√£o criada para realizar a opera√ß√£o Tanh\n",
    "    def tanh(self):\n",
    "        \"\"\"Realiza a opera√ß√£o da tangente hiperb√≥lica\"\"\"\n",
    "        return self.exp() - (- self.exp())/ (self.exp() + 1) - (-self.exp())\n",
    "    \n",
    "    def propagar(self):\n",
    "        pass\n",
    "    \n",
    "    def propagar_tudo(self):\n",
    "        \n",
    "        self.grad = 1\n",
    "        \n",
    "        ordem_topologica = []\n",
    "        \n",
    "        visitados = set()\n",
    "\n",
    "        def constroi_ordem_topologica(v):\n",
    "            if v not in visitados:\n",
    "                visitados.add(v)\n",
    "                for progenitor in v.progenitor:\n",
    "                    constroi_ordem_topologica(progenitor)\n",
    "                ordem_topologica.append(v)\n",
    "\n",
    "        constroi_ordem_topologica(self)\n",
    "        \n",
    "        for vertice in reversed(ordem_topologica):\n",
    "            vertice.propagar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c√≥digo que cria um neur√¥nio artificial, feito em sala\n",
    "\n",
    "class Neuronio_tanh:\n",
    "    def __init__(self, num_dados_entrada):\n",
    "        self.vies = Valor_tanh(random.uniform(-1, 1))\n",
    "        \n",
    "        self.pesos = []\n",
    "        for i in range(num_dados_entrada):\n",
    "            self.pesos.append(Valor_tanh(random.uniform(-1, 1)))\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        \n",
    "        assert len(x) == len(self.pesos)\n",
    "        \n",
    "        soma = 0\n",
    "        for info_entrada, peso_interno in zip(x, self.pesos):\n",
    "            soma += info_entrada * peso_interno\n",
    "            \n",
    "        soma += self.vies  \n",
    "        ### utiliza a Tanh\n",
    "        dado_de_saida = soma.tanh()\n",
    "        \n",
    "        return dado_de_saida       \n",
    "    \n",
    "    def parametros(self):\n",
    "        return self.pesos + [self.vies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor(data=30317.419922262237)\n"
     ]
    }
   ],
   "source": [
    "dados_de_entrada = [7, 6, 5, 3]\n",
    "\n",
    "meu_neuronio = Neuronio_tanh(len(dados_de_entrada))\n",
    "\n",
    "print(meu_neuronio(dados_de_entrada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "### c√≥digo que cria uma camada de neur√¥nios, feito em sala de aula\n",
    "class Camada_tanh:\n",
    "    def __init__(self, num_neuronios, num_dados_entrada):\n",
    "        neuronios = []\n",
    "        \n",
    "        for _ in range(num_neuronios):\n",
    "            neuronio = Neuronio_tanh(num_dados_entrada)\n",
    "            neuronios.append(neuronio)\n",
    "            \n",
    "        self.neuronios = neuronios     \n",
    "        \n",
    "    def __call__(self, x):\n",
    "        dados_de_saida = []\n",
    "        \n",
    "        for neuronio in self.neuronios:\n",
    "            informacao = neuronio(x)\n",
    "            dados_de_saida.append(informacao)\n",
    "            \n",
    "        if len(dados_de_saida) == 1:\n",
    "            return dados_de_saida[0]\n",
    "        else:        \n",
    "            return dados_de_saida  \n",
    "    \n",
    "    def parametros(self):\n",
    "        params = []\n",
    "        \n",
    "        for neuronio in self.neuronios:\n",
    "            params_neuronio = neuronio.parametros()\n",
    "            params.extend(params_neuronio)\n",
    "        \n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.085135095316966, 5.315977391065889, 12.14226239404557, -1.4430334559402596]\n"
     ]
    }
   ],
   "source": [
    "dados_de_entrada = [7, 6, 5, 3]\n",
    "num_neuronios = 4\n",
    "\n",
    "minha_camada = Camada_linear(num_neuronios, len(dados_de_entrada))\n",
    "\n",
    "print(minha_camada(dados_de_entrada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "### classe que cria a rede neural MLP feito em sala de aula\n",
    "class MLP_tanh:\n",
    "    def __init__(self, num_dados_entrada, num_neuronios_por_camada):\n",
    "        \n",
    "        percurso = [num_dados_entrada] + num_neuronios_por_camada\n",
    "        \n",
    "        camadas = []\n",
    "        \n",
    "        for i in range(len(num_neuronios_por_camada)):\n",
    "            camada = Camada_tanh(num_neuronios_por_camada[i], percurso[i])\n",
    "            camadas.append(camada)\n",
    "            \n",
    "        self.camadas = camadas\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for camada in self.camadas:\n",
    "            x = camada(x)\n",
    "        return x\n",
    "    \n",
    "    def parametros(self):\n",
    "        params = []\n",
    "        \n",
    "        for camada in self.camadas:\n",
    "            parametros_camada = camada.parametros()\n",
    "            params.extend(parametros_camada)\n",
    "            \n",
    "        return params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-51.669776935270214, -16.810196787272908, -22.085978390503104, 30.93166769555357, -57.89753517564357]\n"
     ]
    }
   ],
   "source": [
    "dados_de_entrada = [7, 6, 5, 3]\n",
    "num_neuronios_por_camada = [2, 4, 5]\n",
    "\n",
    "minha_mlp = MLP_linear(len(dados_de_entrada), num_neuronios_por_camada)\n",
    "\n",
    "resultado = minha_mlp(dados_de_entrada)\n",
    "\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### ‚ûó Fun√ß√£o ReLu\n",
    "\n",
    "A fun√ß√£o Relu √© chamada de unidade linear retificada, e √© dado por: $$ f(x) = max(0,x) $$. √â a fun√ß√£o de ativa√ß√£o mais utilizada em redes neurais. √â uma fun√ß√£o n√£o linear, o que facilita a propaga√ß√£o dos erros atrav√©s do backpropagation. Essa fun√ß√£o ir√° produzir o m√°ximo entre a sua entrada e 0. Para entradas positivas, a fun√ß√£o √© igual a entrada, para fun√ß√µes negativas a sa√≠da √© igual a 0. Esse tipo de fun√ß√£o evita que ocorra o desaparecimento do gradiente, que √© um problema que surge o gradiente usado para atualizar os pesos das redes se torna muito pequeno ou \"desaparece\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c√≥digo que cria a classe Valor para opera√ß√µes matem√°ticas feito em sala de aula \n",
    "import numpy as np\n",
    "\n",
    "class Valor_ReLu:\n",
    "    def __init__(self, data, progenitor=(), operador_mae=\"\", rotulo=\"\"):\n",
    "        self.data = data\n",
    "        self.progenitor = progenitor\n",
    "        self.operador_mae = operador_mae\n",
    "        self.rotulo = rotulo\n",
    "\n",
    "        self.grad = 0\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Valor(data={self.data})\"\n",
    "    \n",
    "    def __add__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: self + outro_valor.\"\"\"\n",
    "        \n",
    "        if not isinstance(outro_valor, Valor_ReLu):\n",
    "            outro_valor = Valor_ReLu(outro_valor)\n",
    "            \n",
    "        progenitor = (self, outro_valor)\n",
    "        data = self.data + outro_valor.data\n",
    "        operador_mae = \"+\"\n",
    "        resultado = Valor_ReLu(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_adicao():\n",
    "            self.grad += resultado.grad\n",
    "            outro_valor.grad += resultado.grad\n",
    "            \n",
    "        resultado.propagar = propagar_adicao\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __mul__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: self * outro_valor.\"\"\"\n",
    "        \n",
    "        if not isinstance(outro_valor, Valor_ReLu):\n",
    "            outro_valor = Valor_ReLu(outro_valor)\n",
    "            \n",
    "        progenitor = (self, outro_valor)\n",
    "        data = self.data * outro_valor.data\n",
    "        operador_mae = \"*\"\n",
    "        resultado = Valor_ReLu(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_multiplicacao():\n",
    "            self.grad += resultado.grad * outro_valor.data # grad_filho * derivada filho em rela√ß√£o a m√£e\n",
    "            outro_valor.grad += resultado.grad * self.data\n",
    "            \n",
    "        resultado.propagar = propagar_multiplicacao\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def exp(self):\n",
    "        \"\"\"Realiza a opera√ß√£o: exp(self)\"\"\"\n",
    "        progenitor = (self, )\n",
    "        data = math.exp(self.data)\n",
    "        operador_mae = \"exp\"\n",
    "        resultado = Valor_ReLu(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_exp():\n",
    "            self.grad += resultado.grad * data \n",
    "        \n",
    "        resultado.propagar = propagar_exp\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __pow__(self, expoente):\n",
    "        \"\"\"Realiza a opera√ß√£o: self ** expoente\"\"\"\n",
    "        assert isinstance(expoente, (int, float))\n",
    "        progenitor = (self, )\n",
    "        data = self.data ** expoente\n",
    "        operador_mae = f\"**{expoente}\"\n",
    "        resultado = Valor_ReLu(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_pow():\n",
    "            self.grad += resultado.grad * (expoente * self.data ** (expoente - 1))\n",
    "        \n",
    "        resultado.propagar = propagar_pow\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __truediv__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: self / outro_valor\"\"\"\n",
    "        return self * outro_valor ** (-1)\n",
    "    \n",
    "    def __neg__(self):\n",
    "        \"\"\"Realiza a opera√ß√£o: -self\"\"\"\n",
    "        return self * -1\n",
    "    \n",
    "    def __sub__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: self - outro_valor\"\"\"\n",
    "        return self + (-outro_valor)\n",
    "    \n",
    "    def __radd__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: outro_valor + self\"\"\"\n",
    "        return self + outro_valor\n",
    "    \n",
    "    def __rmul__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: outro_valor * self\"\"\"\n",
    "        return self * outro_valor\n",
    "    \n",
    "    # Dentro da classe Valor_ReLu\n",
    "    def relu(self):\n",
    "        data = max(0, self.data)\n",
    "        resultado = Valor_ReLu(data, (self,), \"ReLU\")\n",
    "\n",
    "        def propagar_relu():\n",
    "            self.grad += resultado.grad * (1.0 if self.data > 0 else 0.0)\n",
    "\n",
    "        resultado.propagar = propagar_relu\n",
    "        \n",
    "        return resultado\n",
    "\n",
    "            \n",
    "    def propagar(self):\n",
    "        pass\n",
    "    \n",
    "    def propagar_tudo(self):\n",
    "        \n",
    "        self.grad = 1\n",
    "        \n",
    "        ordem_topologica = []\n",
    "        \n",
    "        visitados = set()\n",
    "\n",
    "        def constroi_ordem_topologica(v):\n",
    "            if v not in visitados:\n",
    "                visitados.add(v)\n",
    "                for progenitor in v.progenitor:\n",
    "                    constroi_ordem_topologica(progenitor)\n",
    "                ordem_topologica.append(v)\n",
    "\n",
    "        constroi_ordem_topologica(self)\n",
    "        \n",
    "        for vertice in reversed(ordem_topologica):\n",
    "            vertice.propagar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c√≥digo que cria um neur√¥nio artificial, feito em sala\n",
    "import random\n",
    "\n",
    "class Neuronio_ReLu:\n",
    "    def __init__(self, num_dados_entrada):\n",
    "        self.vies = Valor_ReLu(random.uniform(-1, 1))\n",
    "        \n",
    "        self.pesos = []\n",
    "        for i in range(num_dados_entrada):\n",
    "            self.pesos.append(Valor_ReLu(random.uniform(-1, 1)))\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        assert len(x) == len(self.pesos)\n",
    "        soma = Valor_ReLu(0)\n",
    "        for xi, wi in zip(x, self.pesos):\n",
    "            soma += xi * wi\n",
    "        soma += self.vies\n",
    "        return soma.relu()\n",
    "\n",
    "       \n",
    "    \n",
    "    def parametros(self):\n",
    "        return self.pesos + [self.vies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor(data=3.220879766578734)\n"
     ]
    }
   ],
   "source": [
    "dados_de_entrada = [Valor_ReLu(v) for v in [5, 12, 4, 6, 7, 13]]\n",
    "\n",
    "meu_neuronio = Neuronio_ReLu(len(dados_de_entrada))\n",
    "\n",
    "print(meu_neuronio(dados_de_entrada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "### c√≥digo que cria uma camada de neur√¥nios, feito em sala de aula\n",
    "class Camada_ReLu:\n",
    "    def __init__(self, num_neuronios, num_dados_entrada):\n",
    "        neuronios = []\n",
    "        \n",
    "        for _ in range(num_neuronios):\n",
    "            neuronio = Neuronio_ReLu(num_dados_entrada)\n",
    "            neuronios.append(neuronio)\n",
    "            \n",
    "        self.neuronios = neuronios     \n",
    "        \n",
    "    def __call__(self, x):\n",
    "        dados_de_saida = []\n",
    "        \n",
    "        for neuronio in self.neuronios:\n",
    "            informacao = neuronio(x)\n",
    "            dados_de_saida.append(informacao)\n",
    "            \n",
    "        if len(dados_de_saida) == 1:\n",
    "            return dados_de_saida[0]\n",
    "        else:        \n",
    "            return dados_de_saida  \n",
    "    \n",
    "    def parametros(self):\n",
    "        params = []\n",
    "        \n",
    "        for neuronio in self.neuronios:\n",
    "            params_neuronio = neuronio.parametros()\n",
    "            params.extend(params_neuronio)\n",
    "        \n",
    "        return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Valor(data=1.2279144192414997), Valor(data=0), Valor(data=8.930426892548468), Valor(data=0), Valor(data=0), Valor(data=3.780764822425252), Valor(data=6.207803750813268)]\n"
     ]
    }
   ],
   "source": [
    "dados_de_entrada = [Valor_ReLu(v) for v in [5, 12, 4, 6, 7, 13]]\n",
    "num_neuronios = 7\n",
    "\n",
    "minha_camada = Camada_ReLu(num_neuronios, len(dados_de_entrada))\n",
    "\n",
    "print(minha_camada(dados_de_entrada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "### classe que cria a rede neural MLP feito em sala de aula\n",
    "class MLP_ReLu:\n",
    "    def __init__(self, num_dados_entrada, num_neuronios_por_camada):\n",
    "        \n",
    "        percurso = [num_dados_entrada] + num_neuronios_por_camada\n",
    "        \n",
    "        camadas = []\n",
    "        \n",
    "        for i in range(len(num_neuronios_por_camada)):\n",
    "            camada = Camada_ReLu(num_neuronios_por_camada[i], percurso[i])\n",
    "            camadas.append(camada)\n",
    "            \n",
    "        self.camadas = camadas\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for camada in self.camadas:\n",
    "            x = camada(x)\n",
    "        return x\n",
    "    \n",
    "    def parametros(self):\n",
    "        params = []\n",
    "        \n",
    "        for camada in self.camadas:\n",
    "            parametros_camada = camada.parametros()\n",
    "            params.extend(parametros_camada)\n",
    "            \n",
    "        return params\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Valor(data=7.155983594746221), Valor(data=0), Valor(data=11.133500629741395)]\n"
     ]
    }
   ],
   "source": [
    "dados_de_entrada = [Valor_ReLu(v) for v in [5, 12, 4, 6, 7, 13]]\n",
    "num_neuronios_por_camada = [5, 8, 3]\n",
    "\n",
    "minha_mlp = MLP_ReLu(len(dados_de_entrada), num_neuronios_por_camada)\n",
    "\n",
    "resultado = minha_mlp(dados_de_entrada)\n",
    "\n",
    "print(resultado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### üìä Conclus√£o:\n",
    "\n",
    "Nesse notebook, exploramos outras fun√ß√µes de ativa√ß√£o que n√£o foram exploradas em sala, o que permitiu a compreens√£o do funcionamento matem√°tico e computacional de diferentes fun√ß√µes. Pesquisar sobre as diferen√ßas em rela√ß√£o a fun√ß√£o sigmoide tornou poss√≠vel entender que, para diferentes problemas, √© necess√°rio identificar qual a fun√ß√£o de ativa√ß√£o ideal para se obter o resultado esperado.\n",
    "\n",
    "----\n",
    "### üìö Refer√™ncias:\n",
    "\n",
    "CAP√çTULO 8 ‚Äì Fun√ß√£o de Ativa√ß√£o. Deep Learning Book, [s.d.]. Dispon√≠vel em: <https://www.deeplearningbook.com.br/funcao-de-ativacao/>. Acesso em: 1 abr. 2025.\n",
    "\n",
    "FUN√á√ÉO softmax. Wikip√©dia: a enciclop√©dia livre, [s.d.]. Dispon√≠vel em: <https://pt.wikipedia.org/wiki/Fun%C3%A7%C3%A3o_softmax>. Acesso em: 1 abr. 2025.\n",
    "\n",
    "TANGENTE hiperb√≥lica. Wikip√©dia: a enciclop√©dia livre, [s.d.]. Dispon√≠vel em: <https://pt.wikipedia.org/wiki/Tangente_hiperb%C3%B3lica>. Acesso em: 1 abr. 2025.\n",
    "\n",
    "CHATGPT. OpenAI, [s.d.]. Dispon√≠vel em: <https://chatgpt.com/share/67ec43f2-6d60-8005-96b7-0647b4325879>. Acesso em: 1 abr. 2025.\n",
    "\n",
    "GEMINI. Google AI, [s.d.]. Dispon√≠vel em: <https://gemini.google.com/app/b06bb6fbe78b91fc?hl=pt-BR>. Acesso em: 1 abr. 2025.\n",
    "\n",
    "DATACAMP. Rectified Linear Unit (ReLU): o que √© e como funciona? DataCamp, 2023. Dispon√≠vel em: https://www.datacamp.com/pt/blog/rectified-linear-unit-relu. Acesso em: 9 jun. 2025."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
