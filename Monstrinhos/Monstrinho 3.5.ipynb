{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<span style=\"font-family: 'Palatino Linotype', serif;\">‚öôÔ∏è‚ö°Forma, fun√ß√£o e ativa√ß√£o</span>**\n",
    "----\n",
    "*<span style=\"font-family: 'Angilla Tattoo'\"> \"\"Moldaremos a forma, otimizaremos a fun√ß√£o e executataremos a ativa√ß√£o da magia pato-digital para consquistar o Reino de Lumi! ü¶Üüíª‚ú®\"\"</span>*\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src = \"Maga Forma, Fun√ß√£o e ativa√ß√£o.jpg\" alt = \"Maga FFA\" width = 300>\n",
    "</div>\n",
    "\n",
    "----\n",
    " **Objetivo:** Nesse notebook, implementei 3 as fun√ß√µes de ativa√ß√£o fun√ß√£o liner, Tahn e Softmax, na rede neural feita em python em sala da aula. Realizo uma breve explica√ß√£o sobre as fun√ß√µes, mostando suas equa√ß√µes e diferen√ßas em rela√ß√£o a fun√ß√£o sigmoidal, e por fim s√£o feitos testes simples para comprovar seu funcionamento.\n",
    " \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìê A fun√ß√£o linear\n",
    "\n",
    "A fun√ß√£o √© definida como $$ f(x) = ax $$ por√©m, a fun√ß√£o linear √© constante, o que significa que o valor de sua derivada n√£o depende de X. Nesse sentido, o valor do gradiente local no backpropagation ser√° sempre o mesmo. Isso √© um grande problema, pois n√£o podemos melhorar a fun√ß√£o de perda \"loss\", e a sa√≠da final da nossa rede neural ser√° uma transforma√ß√£o linear dos dados de entrada. Isso faz com que essa fun√ß√£o de entrada seja interessante em contextos de problemas simples, onde desejamos que os resultados sejam interpret√°veis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c√≥digo que cria a classe Valor para opera√ß√µes matem√°ticas feito em sala de aula \n",
    "import math\n",
    "\n",
    "class Valor_linear:\n",
    "    def __init__(self, data, progenitor=(), operador_mae=\"\", rotulo=\"\"):\n",
    "        self.data = data\n",
    "        self.progenitor = progenitor\n",
    "        self.operador_mae = operador_mae\n",
    "        self.rotulo = rotulo\n",
    "        self.grad = 0\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Valor(data={self.data})\"\n",
    "    \n",
    "    def __add__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: self + outro_valor.\"\"\"\n",
    "        \n",
    "        if not isinstance(outro_valor, Valor_linear):\n",
    "            outro_valor = Valor_linear(outro_valor)\n",
    "            \n",
    "        progenitor = (self, outro_valor)\n",
    "        data = self.data + outro_valor.data\n",
    "        operador_mae = \"+\"\n",
    "        resultado = Valor_linear(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_adicao():\n",
    "            self.grad += resultado.grad\n",
    "            outro_valor.grad += resultado.grad\n",
    "            \n",
    "        resultado.propagar = propagar_adicao\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __mul__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: self * outro_valor.\"\"\"\n",
    "        \n",
    "        if not isinstance(outro_valor, Valor_linear):\n",
    "            outro_valor = Valor_linear(outro_valor)\n",
    "            \n",
    "        progenitor = (self, outro_valor)\n",
    "        data = self.data * outro_valor.data\n",
    "        operador_mae = \"*\"\n",
    "        resultado = Valor_linear(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_multiplicacao():\n",
    "            self.grad += resultado.grad * outro_valor.data # grad_filho * derivada filho em rela√ß√£o a m√£e\n",
    "            outro_valor.grad += resultado.grad * self.data\n",
    "            \n",
    "        resultado.propagar = propagar_multiplicacao\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def exp(self):\n",
    "        \"\"\"Realiza a opera√ß√£o: exp(self)\"\"\"\n",
    "        progenitor = (self, )\n",
    "        data = math.exp(self.data)\n",
    "        operador_mae = \"exp\"\n",
    "        resultado = Valor_linear(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_exp():\n",
    "            self.grad += resultado.grad * data \n",
    "        \n",
    "        resultado.propagar = propagar_exp\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __pow__(self, expoente):\n",
    "        \"\"\"Realiza a opera√ß√£o: self ** expoente\"\"\"\n",
    "        assert isinstance(expoente, (int, float))\n",
    "        progenitor = (self, )\n",
    "        data = self.data ** expoente\n",
    "        operador_mae = f\"**{expoente}\"\n",
    "        resultado = Valor_linear(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_pow():\n",
    "            self.grad += resultado.grad * (expoente * self.data ** (expoente - 1))\n",
    "        \n",
    "        resultado.propagar = propagar_pow\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __truediv__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: self / outro_valor\"\"\"\n",
    "        return self * outro_valor ** (-1)\n",
    "    \n",
    "    def __neg__(self):\n",
    "        \"\"\"Realiza a opera√ß√£o: -self\"\"\"\n",
    "        return self * -1\n",
    "    \n",
    "    def __sub__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: self - outro_valor\"\"\"\n",
    "        return self + (-outro_valor)\n",
    "    \n",
    "    def __radd__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: outro_valor + self\"\"\"\n",
    "        return self + outro_valor\n",
    "    \n",
    "    def __rmul__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: outro_valor * self\"\"\"\n",
    "        return self * outro_valor\n",
    "    \n",
    "    ### fun√ß√£o criada para realizar uma opera√ß√£o linear para cte = 2\n",
    "    def funcao_linear(self):\n",
    "        \"\"\"Realiza a opera√ß√£o: x * cte = 2)\"\"\"\n",
    "        return self.data * 2\n",
    "    \n",
    "    def propagar(self):\n",
    "        pass\n",
    "    \n",
    "    def propagar_tudo(self):\n",
    "        \n",
    "        self.grad = 1\n",
    "        \n",
    "        ordem_topologica = []\n",
    "        \n",
    "        visitados = set()\n",
    "\n",
    "        def constroi_ordem_topologica(v):\n",
    "            if v not in visitados:\n",
    "                visitados.add(v)\n",
    "                for progenitor in v.progenitor:\n",
    "                    constroi_ordem_topologica(progenitor)\n",
    "                ordem_topologica.append(v)\n",
    "\n",
    "        constroi_ordem_topologica(self)\n",
    "        \n",
    "        for vertice in reversed(ordem_topologica):\n",
    "            vertice.propagar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c√≥digo que cria um neur√¥nio artificial, feito em sala\n",
    "import random\n",
    "\n",
    "class Neuronio_linear:\n",
    "    def __init__(self, num_dados_entrada):\n",
    "        self.vies = Valor_linear(random.uniform(-1, 1))\n",
    "        \n",
    "        self.pesos = []\n",
    "        for i in range(num_dados_entrada):\n",
    "            self.pesos.append(Valor_linear(random.uniform(-1, 1)))\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        \n",
    "        assert len(x) == len(self.pesos)\n",
    "        \n",
    "        soma = 0\n",
    "        for info_entrada, peso_interno in zip(x, self.pesos):\n",
    "            soma += info_entrada * peso_interno\n",
    "            \n",
    "        soma += self.vies  \n",
    "        ### utiliza a fun√ß√£o linear\n",
    "        dado_de_saida = soma.funcao_linear()\n",
    "        \n",
    "        return dado_de_saida       \n",
    "    \n",
    "    def parametros(self):\n",
    "        return self.pesos + [self.vies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2029610541699678\n"
     ]
    }
   ],
   "source": [
    "dados_de_entrada = [2, 3]\n",
    "\n",
    "meu_neuronio = Neuronio_linear(len(dados_de_entrada))\n",
    "\n",
    "print(meu_neuronio(dados_de_entrada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "### c√≥digo que cria uma camada de neur√¥nios, feito em sala de aula\n",
    "class Camada_linear:\n",
    "    def __init__(self, num_neuronios, num_dados_entrada):\n",
    "        neuronios = []\n",
    "        \n",
    "        for _ in range(num_neuronios):\n",
    "            neuronio = Neuronio_linear(num_dados_entrada)\n",
    "            neuronios.append(neuronio)\n",
    "            \n",
    "        self.neuronios = neuronios     \n",
    "        \n",
    "    def __call__(self, x):\n",
    "        dados_de_saida = []\n",
    "        \n",
    "        for neuronio in self.neuronios:\n",
    "            informacao = neuronio(x)\n",
    "            dados_de_saida.append(informacao)\n",
    "            \n",
    "        if len(dados_de_saida) == 1:\n",
    "            return dados_de_saida[0]\n",
    "        else:        \n",
    "            return dados_de_saida  \n",
    "    \n",
    "    def parametros(self):\n",
    "        params = []\n",
    "        \n",
    "        for neuronio in self.neuronios:\n",
    "            params_neuronio = neuronio.parametros()\n",
    "            params.extend(params_neuronio)\n",
    "        \n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.0096194300279353, -3.605286388172126, 5.542409510143863, 2.6428576450306225, 1.4059801547422417]\n"
     ]
    }
   ],
   "source": [
    "dados_de_entrada = [2, 3]\n",
    "num_neuronios = 5\n",
    "\n",
    "minha_camada = Camada_linear(num_neuronios, len(dados_de_entrada))\n",
    "\n",
    "print(minha_camada(dados_de_entrada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "### classe que cria a rede neural MLP feito em sala de aula\n",
    "class MLP_linear:\n",
    "    def __init__(self, num_dados_entrada, num_neuronios_por_camada):\n",
    "        \n",
    "        percurso = [num_dados_entrada] + num_neuronios_por_camada\n",
    "        \n",
    "        camadas = []\n",
    "        \n",
    "        for i in range(len(num_neuronios_por_camada)):\n",
    "            camada = Camada_linear(num_neuronios_por_camada[i], percurso[i])\n",
    "            camadas.append(camada)\n",
    "            \n",
    "        self.camadas = camadas\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for camada in self.camadas:\n",
    "            x = camada(x)\n",
    "        return x\n",
    "    \n",
    "    def parametros(self):\n",
    "        params = []\n",
    "        \n",
    "        for camada in self.camadas:\n",
    "            parametros_camada = camada.parametros()\n",
    "            params.extend(parametros_camada)\n",
    "            \n",
    "        return params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15.020432300626572, -19.252502717781372, 4.50863805303381, -0.7858626891939915, 8.386044633544987]\n"
     ]
    }
   ],
   "source": [
    "dados_de_entrada = [2, 3]\n",
    "num_neuronios_por_camada = [2, 4, 5]\n",
    "\n",
    "minha_mlp = MLP_linear(len(dados_de_entrada), num_neuronios_por_camada)\n",
    "\n",
    "resultado = minha_mlp(dados_de_entrada)\n",
    "\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- \n",
    "\n",
    "###  üî¢ A fun√ß√£o Tanh\n",
    "\n",
    "A fun√ß√£o Tanh, ou tangente hiperb√≥lica, √© uma vers√£o escalonada da fun√ß√£o sigmoide, dada por $$ Tahn(x) = \\frac {e^x - e^{-x}}{e^x - e^{-x}} $$ A fun√ß√£o Tanh √© sim√©trica entre os valore 1 e -1, diferente do que ocorre na fun√ß√£o sigmoide, que √© sim√©trica entre 0 e 1. Essa simetria em rela√ß√£o a origem √© interessante para a rede neural na medida que evita que os valores propagados para o pr√≥ximo neuronio sejam sempre positivos. Como a fun√ß√£o n√£o √© linear, podemos realizar o backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c√≥digo que cria a classe Valor para opera√ß√µes matem√°ticas feito em sala de aula \n",
    "\n",
    "class Valor_tanh:\n",
    "    def __init__(self, data, progenitor=(), operador_mae=\"\", rotulo=\"\"):\n",
    "        self.data = data\n",
    "        self.progenitor = progenitor\n",
    "        self.operador_mae = operador_mae\n",
    "        self.rotulo = rotulo\n",
    "        self.grad = 0\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Valor(data={self.data})\"\n",
    "    \n",
    "    def __add__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: self + outro_valor.\"\"\"\n",
    "        \n",
    "        if not isinstance(outro_valor, Valor_tanh):\n",
    "            outro_valor = Valor_tanh(outro_valor)\n",
    "            \n",
    "        progenitor = (self, outro_valor)\n",
    "        data = self.data + outro_valor.data\n",
    "        operador_mae = \"+\"\n",
    "        resultado = Valor_tanh(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_adicao():\n",
    "            self.grad += resultado.grad\n",
    "            outro_valor.grad += resultado.grad\n",
    "            \n",
    "        resultado.propagar = propagar_adicao\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __mul__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: self * outro_valor.\"\"\"\n",
    "        \n",
    "        if not isinstance(outro_valor, Valor_tanh):\n",
    "            outro_valor = Valor_tanh(outro_valor)\n",
    "            \n",
    "        progenitor = (self, outro_valor)\n",
    "        data = self.data * outro_valor.data\n",
    "        operador_mae = \"*\"\n",
    "        resultado = Valor_tanh(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_multiplicacao():\n",
    "            self.grad += resultado.grad * outro_valor.data # grad_filho * derivada filho em rela√ß√£o a m√£e\n",
    "            outro_valor.grad += resultado.grad * self.data\n",
    "            \n",
    "        resultado.propagar = propagar_multiplicacao\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def exp(self):\n",
    "        \"\"\"Realiza a opera√ß√£o: exp(self)\"\"\"\n",
    "        progenitor = (self, )\n",
    "        data = math.exp(self.data)\n",
    "        operador_mae = \"exp\"\n",
    "        resultado = Valor_tanh(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_exp():\n",
    "            self.grad += resultado.grad * data \n",
    "        \n",
    "        resultado.propagar = propagar_exp\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __pow__(self, expoente):\n",
    "        \"\"\"Realiza a opera√ß√£o: self ** expoente\"\"\"\n",
    "        assert isinstance(expoente, (int, float))\n",
    "        progenitor = (self, )\n",
    "        data = self.data ** expoente\n",
    "        operador_mae = f\"**{expoente}\"\n",
    "        resultado = Valor_tanh(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_pow():\n",
    "            self.grad += resultado.grad * (expoente * self.data ** (expoente - 1))\n",
    "        \n",
    "        resultado.propagar = propagar_pow\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __truediv__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: self / outro_valor\"\"\"\n",
    "        return self * outro_valor ** (-1)\n",
    "    \n",
    "    def __neg__(self):\n",
    "        \"\"\"Realiza a opera√ß√£o: -self\"\"\"\n",
    "        return self * -1\n",
    "    \n",
    "    def __sub__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: self - outro_valor\"\"\"\n",
    "        return self + (-outro_valor)\n",
    "    \n",
    "    def __radd__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: outro_valor + self\"\"\"\n",
    "        return self + outro_valor\n",
    "    \n",
    "    def __rmul__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: outro_valor * self\"\"\"\n",
    "        return self * outro_valor\n",
    "    \n",
    "    ### fun√ß√£o criada para realizar a opera√ß√£o Tanh\n",
    "    def tanh(self):\n",
    "        \"\"\"Realiza a opera√ß√£o da tangente hiperb√≥lica\"\"\"\n",
    "        return self.exp() - (-self.exp())/ (self.exp() + 1) - (-self.exp())\n",
    "    \n",
    "    def propagar(self):\n",
    "        pass\n",
    "    \n",
    "    def propagar_tudo(self):\n",
    "        \n",
    "        self.grad = 1\n",
    "        \n",
    "        ordem_topologica = []\n",
    "        \n",
    "        visitados = set()\n",
    "\n",
    "        def constroi_ordem_topologica(v):\n",
    "            if v not in visitados:\n",
    "                visitados.add(v)\n",
    "                for progenitor in v.progenitor:\n",
    "                    constroi_ordem_topologica(progenitor)\n",
    "                ordem_topologica.append(v)\n",
    "\n",
    "        constroi_ordem_topologica(self)\n",
    "        \n",
    "        for vertice in reversed(ordem_topologica):\n",
    "            vertice.propagar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c√≥digo que cria um neur√¥nio artificial, feito em sala\n",
    "\n",
    "class Neuronio_tanh:\n",
    "    def __init__(self, num_dados_entrada):\n",
    "        self.vies = Valor_tanh(random.uniform(-1, 1))\n",
    "        \n",
    "        self.pesos = []\n",
    "        for i in range(num_dados_entrada):\n",
    "            self.pesos.append(Valor_tanh(random.uniform(-1, 1)))\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        \n",
    "        assert len(x) == len(self.pesos)\n",
    "        \n",
    "        soma = 0\n",
    "        for info_entrada, peso_interno in zip(x, self.pesos):\n",
    "            soma += info_entrada * peso_interno\n",
    "            \n",
    "        soma += self.vies  \n",
    "        ### utiliza a Tanh\n",
    "        dado_de_saida = soma.tanh()\n",
    "        \n",
    "        return dado_de_saida       \n",
    "    \n",
    "    def parametros(self):\n",
    "        return self.pesos + [self.vies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor(data=99931.095333284)\n"
     ]
    }
   ],
   "source": [
    "dados_de_entrada = [7, 6, 5, 3]\n",
    "\n",
    "meu_neuronio = Neuronio_tanh(len(dados_de_entrada))\n",
    "\n",
    "print(meu_neuronio(dados_de_entrada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "### c√≥digo que cria uma camada de neur√¥nios, feito em sala de aula\n",
    "class Camada_tanh:\n",
    "    def __init__(self, num_neuronios, num_dados_entrada):\n",
    "        neuronios = []\n",
    "        \n",
    "        for _ in range(num_neuronios):\n",
    "            neuronio = Neuronio_tanh(num_dados_entrada)\n",
    "            neuronios.append(neuronio)\n",
    "            \n",
    "        self.neuronios = neuronios     \n",
    "        \n",
    "    def __call__(self, x):\n",
    "        dados_de_saida = []\n",
    "        \n",
    "        for neuronio in self.neuronios:\n",
    "            informacao = neuronio(x)\n",
    "            dados_de_saida.append(informacao)\n",
    "            \n",
    "        if len(dados_de_saida) == 1:\n",
    "            return dados_de_saida[0]\n",
    "        else:        \n",
    "            return dados_de_saida  \n",
    "    \n",
    "    def parametros(self):\n",
    "        params = []\n",
    "        \n",
    "        for neuronio in self.neuronios:\n",
    "            params_neuronio = neuronio.parametros()\n",
    "            params.extend(params_neuronio)\n",
    "        \n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.62561314364077, -8.920461469161356, 1.358341458988189, -12.95110806798985]\n"
     ]
    }
   ],
   "source": [
    "dados_de_entrada = [7, 6, 5, 3]\n",
    "num_neuronios = 4\n",
    "\n",
    "minha_camada = Camada_linear(num_neuronios, len(dados_de_entrada))\n",
    "\n",
    "print(minha_camada(dados_de_entrada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "### classe que cria a rede neural MLP feito em sala de aula\n",
    "class MLP_tanh:\n",
    "    def __init__(self, num_dados_entrada, num_neuronios_por_camada):\n",
    "        \n",
    "        percurso = [num_dados_entrada] + num_neuronios_por_camada\n",
    "        \n",
    "        camadas = []\n",
    "        \n",
    "        for i in range(len(num_neuronios_por_camada)):\n",
    "            camada = Camada_tanh(num_neuronios_por_camada[i], percurso[i])\n",
    "            camadas.append(camada)\n",
    "            \n",
    "        self.camadas = camadas\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for camada in self.camadas:\n",
    "            x = camada(x)\n",
    "        return x\n",
    "    \n",
    "    def parametros(self):\n",
    "        params = []\n",
    "        \n",
    "        for camada in self.camadas:\n",
    "            parametros_camada = camada.parametros()\n",
    "            params.extend(parametros_camada)\n",
    "            \n",
    "        return params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53.03678140995267, -11.96504168573132, -56.55977314905519, 0.6011882921724783, -31.452674881460602]\n"
     ]
    }
   ],
   "source": [
    "dados_de_entrada = [7, 6, 5, 3]\n",
    "num_neuronios_por_camada = [2, 4, 5]\n",
    "\n",
    "minha_mlp = MLP_linear(len(dados_de_entrada), num_neuronios_por_camada)\n",
    "\n",
    "resultado = minha_mlp(dados_de_entrada)\n",
    "\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### ‚ûó Fun√ß√£o SoftMax\n",
    "\n",
    "A fun√ß√£o SoftMax √© um tipo de fun√ß√£o sigm√≥ide, √∫til para lidar com problemas de classifica√ß√£o. Ela converte um vetor de K n√∫meros reais e os normaliza em uma distribui√ß√£o de probabilidade de K resultados poss√≠veis. Isso quer dizer que, a entrada da fun√ß√£o ser√° um vetor contendo K n√∫meros. Esses n√∫meros ser√£o normalizados, de forma que sua soma final seja equivalente a 1 e represente uma probabilidade. A fun√ß√£o √© dada por $$ \\sigma(z)_i = \\frac{e^{zi}}{\\sum^z_{j = 1} e^{zj}}$$ pra i = 1. Ou seja, √© aplicada a fun√ß√£o exponencial para cada elemento de entrada Z e os valores s√£o normalizados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c√≥digo que cria a classe Valor para opera√ß√µes matem√°ticas feito em sala de aula \n",
    "import numpy as np\n",
    "\n",
    "class Valor_SoftMax:\n",
    "    def __init__(self, data, progenitor=(), operador_mae=\"\", rotulo=\"\"):\n",
    "        self.data = data\n",
    "        self.progenitor = progenitor\n",
    "        self.operador_mae = operador_mae\n",
    "        self.rotulo = rotulo\n",
    "        self.grad = 0\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Valor(data={self.data})\"\n",
    "    \n",
    "    def __add__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: self + outro_valor.\"\"\"\n",
    "        \n",
    "        if not isinstance(outro_valor, Valor_SoftMax):\n",
    "            outro_valor = Valor_SoftMax(outro_valor)\n",
    "            \n",
    "        progenitor = (self, outro_valor)\n",
    "        data = self.data + outro_valor.data\n",
    "        operador_mae = \"+\"\n",
    "        resultado = Valor_SoftMax(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_adicao():\n",
    "            self.grad += resultado.grad\n",
    "            outro_valor.grad += resultado.grad\n",
    "            \n",
    "        resultado.propagar = propagar_adicao\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __mul__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: self * outro_valor.\"\"\"\n",
    "        \n",
    "        if not isinstance(outro_valor, Valor_SoftMax):\n",
    "            outro_valor = Valor_SoftMax(outro_valor)\n",
    "            \n",
    "        progenitor = (self, outro_valor)\n",
    "        data = self.data * outro_valor.data\n",
    "        operador_mae = \"*\"\n",
    "        resultado = Valor_SoftMax(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_multiplicacao():\n",
    "            self.grad += resultado.grad * outro_valor.data # grad_filho * derivada filho em rela√ß√£o a m√£e\n",
    "            outro_valor.grad += resultado.grad * self.data\n",
    "            \n",
    "        resultado.propagar = propagar_multiplicacao\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def exp(self):\n",
    "        \"\"\"Realiza a opera√ß√£o: exp(self)\"\"\"\n",
    "        progenitor = (self, )\n",
    "        data = math.exp(self.data)\n",
    "        operador_mae = \"exp\"\n",
    "        resultado = Valor_SoftMax(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_exp():\n",
    "            self.grad += resultado.grad * data \n",
    "        \n",
    "        resultado.propagar = propagar_exp\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __pow__(self, expoente):\n",
    "        \"\"\"Realiza a opera√ß√£o: self ** expoente\"\"\"\n",
    "        assert isinstance(expoente, (int, float))\n",
    "        progenitor = (self, )\n",
    "        data = self.data ** expoente\n",
    "        operador_mae = f\"**{expoente}\"\n",
    "        resultado = Valor_SoftMax(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_pow():\n",
    "            self.grad += resultado.grad * (expoente * self.data ** (expoente - 1))\n",
    "        \n",
    "        resultado.propagar = propagar_pow\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __truediv__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: self / outro_valor\"\"\"\n",
    "        return self * outro_valor ** (-1)\n",
    "    \n",
    "    def __neg__(self):\n",
    "        \"\"\"Realiza a opera√ß√£o: -self\"\"\"\n",
    "        return self * -1\n",
    "    \n",
    "    def __sub__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: self - outro_valor\"\"\"\n",
    "        return self + (-outro_valor)\n",
    "    \n",
    "    def __radd__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: outro_valor + self\"\"\"\n",
    "        return self + outro_valor\n",
    "    \n",
    "    def __rmul__(self, outro_valor):\n",
    "        \"\"\"Realiza a opera√ß√£o: outro_valor * self\"\"\"\n",
    "        return self * outro_valor\n",
    "    \n",
    "    ### fun√ß√£o criada para realizar a opera√ß√£o SoftMax\n",
    "    def softmax(x):\n",
    "        \"\"\"Realiza a opera√ß√£o SoftMax sobre um vetor x\"\"\"\n",
    "        e_x = np.exp(x - np.max(x))  # essa subtra√ß√£o evita que os valores estourem\n",
    "        return e_x / e_x.sum() # aqui estamos normalizando os n√∫meros\n",
    "        \n",
    "    def propagar(self):\n",
    "        pass\n",
    "    \n",
    "    def propagar_tudo(self):\n",
    "        \n",
    "        self.grad = 1\n",
    "        \n",
    "        ordem_topologica = []\n",
    "        \n",
    "        visitados = set()\n",
    "\n",
    "        def constroi_ordem_topologica(v):\n",
    "            if v not in visitados:\n",
    "                visitados.add(v)\n",
    "                for progenitor in v.progenitor:\n",
    "                    constroi_ordem_topologica(progenitor)\n",
    "                ordem_topologica.append(v)\n",
    "\n",
    "        constroi_ordem_topologica(self)\n",
    "        \n",
    "        for vertice in reversed(ordem_topologica):\n",
    "            vertice.propagar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c√≥digo que cria um neur√¥nio artificial, feito em sala\n",
    "import random\n",
    "\n",
    "class Neuronio_SoftMax:\n",
    "    def __init__(self, num_dados_entrada):\n",
    "        self.vies = Valor_SoftMax(random.uniform(-1, 1))\n",
    "        \n",
    "        self.pesos = []\n",
    "        for i in range(num_dados_entrada):\n",
    "            self.pesos.append(Valor_SoftMax(random.uniform(-1, 1)))\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        assert len(x) == len(self.pesos)\n",
    "        soma = Valor_SoftMax(0)\n",
    "        for xi, wi in zip(x, self.pesos):\n",
    "            soma += xi * wi\n",
    "        soma += self.vies\n",
    "        return soma \n",
    "        \n",
    "        ### utiliza o SoftMax\n",
    "        soft_max(lista_valores)\n",
    "      \n",
    "        return resultado \n",
    "    \n",
    "    def parametros(self):\n",
    "        return self.pesos + [self.vies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor(data=-11.514448220667695)\n"
     ]
    }
   ],
   "source": [
    "dados_de_entrada = [Valor_SoftMax(v) for v in [5, 12, 4, 6, 7, 13]]\n",
    "\n",
    "meu_neuronio = Neuronio_SoftMax(len(dados_de_entrada))\n",
    "\n",
    "print(meu_neuronio(dados_de_entrada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "### c√≥digo que cria uma camada de neur√¥nios, feito em sala de aula\n",
    "class Camada_SoftMax:\n",
    "    def __init__(self, num_neuronios, num_dados_entrada):\n",
    "        neuronios = []\n",
    "        \n",
    "        for _ in range(num_neuronios):\n",
    "            neuronio = Neuronio_SoftMax(num_dados_entrada)\n",
    "            neuronios.append(neuronio)\n",
    "            \n",
    "        self.neuronios = neuronios     \n",
    "        \n",
    "    def __call__(self, x):\n",
    "        dados_de_saida = []\n",
    "        \n",
    "        for neuronio in self.neuronios:\n",
    "            informacao = neuronio(x)\n",
    "            dados_de_saida.append(informacao)\n",
    "            \n",
    "        if len(dados_de_saida) == 1:\n",
    "            return dados_de_saida[0]\n",
    "        else:        \n",
    "            return dados_de_saida  \n",
    "    \n",
    "    def parametros(self):\n",
    "        params = []\n",
    "        \n",
    "        for neuronio in self.neuronios:\n",
    "            params_neuronio = neuronio.parametros()\n",
    "            params.extend(params_neuronio)\n",
    "        \n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Valor(data=14.989757378692323), Valor(data=5.014127832496978), Valor(data=-8.818856820670652), Valor(data=5.434187336946087), Valor(data=10.582332862822586), Valor(data=-0.6174172729290723), Valor(data=-2.8093976126639224)]\n"
     ]
    }
   ],
   "source": [
    "dados_de_entrada = [Valor_SoftMax(v) for v in [5, 12, 4, 6, 7, 13]]\n",
    "num_neuronios = 7\n",
    "\n",
    "minha_camada = Camada_SoftMax(num_neuronios, len(dados_de_entrada))\n",
    "\n",
    "print(minha_camada(dados_de_entrada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "### classe que cria a rede neural MLP feito em sala de aula\n",
    "class MLP_SoftMax:\n",
    "    def __init__(self, num_dados_entrada, num_neuronios_por_camada):\n",
    "        \n",
    "        percurso = [num_dados_entrada] + num_neuronios_por_camada\n",
    "        \n",
    "        camadas = []\n",
    "        \n",
    "        for i in range(len(num_neuronios_por_camada)):\n",
    "            camada = Camada_SoftMax(num_neuronios_por_camada[i], percurso[i])\n",
    "            camadas.append(camada)\n",
    "            \n",
    "        self.camadas = camadas\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for camada in self.camadas:\n",
    "            x = camada(x)\n",
    "        return x\n",
    "    \n",
    "    def parametros(self):\n",
    "        params = []\n",
    "        \n",
    "        for camada in self.camadas:\n",
    "            parametros_camada = camada.parametros()\n",
    "            params.extend(parametros_camada)\n",
    "            \n",
    "        return params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Valor(data=-39.701881028685925), Valor(data=1.2460714667891983), Valor(data=-22.926427433549417)]\n"
     ]
    }
   ],
   "source": [
    "dados_de_entrada = [Valor_SoftMax(v) for v in [5, 12, 4, 6, 7, 13]]\n",
    "num_neuronios_por_camada = [5, 8, 3]\n",
    "\n",
    "minha_mlp = MLP_SoftMax(len(dados_de_entrada), num_neuronios_por_camada)\n",
    "\n",
    "resultado = minha_mlp(dados_de_entrada)\n",
    "\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### üìä Conclus√£o:\n",
    "\n",
    "Nesse notebook, exploramos outras fun√ß√µes de ativa√ß√£o que n√£o foram exploradas em sala, o que permitiu a compreens√£o do funcionamento matem√°tico e computacional de diferentes fun√ß√µes. Pesquisar sobre as diferen√ßas em rela√ß√£o a fun√ß√£o sigmoide tornou poss√≠vel entender que, para diferentes problemas, √© necess√°rio identificar qual a fun√ß√£o de ativa√ß√£o ideal para se obter o resultado esperado.\n",
    "\n",
    "----\n",
    "### üìö Refer√™ncias:\n",
    "\n",
    "CAP√çTULO 8 ‚Äì Fun√ß√£o de Ativa√ß√£o. Deep Learning Book, [s.d.]. Dispon√≠vel em: <https://www.deeplearningbook.com.br/funcao-de-ativacao/>. Acesso em: 1 abr. 2025.\n",
    "\n",
    "FUN√á√ÉO softmax. Wikip√©dia: a enciclop√©dia livre, [s.d.]. Dispon√≠vel em: <https://pt.wikipedia.org/wiki/Fun%C3%A7%C3%A3o_softmax>. Acesso em: 1 abr. 2025.\n",
    "\n",
    "TANGENTE hiperb√≥lica. Wikip√©dia: a enciclop√©dia livre, [s.d.]. Dispon√≠vel em: <https://pt.wikipedia.org/wiki/Tangente_hiperb%C3%B3lica>. Acesso em: 1 abr. 2025.\n",
    "\n",
    "CHATGPT. OpenAI, [s.d.]. Dispon√≠vel em: <https://chatgpt.com/share/67ec43f2-6d60-8005-96b7-0647b4325879>. Acesso em: 1 abr. 2025.\n",
    "\n",
    "GEMINI. Google AI, [s.d.]. Dispon√≠vel em: <https://gemini.google.com/app/b06bb6fbe78b91fc?hl=pt-BR>. Acesso em: 1 abr. 2025."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
